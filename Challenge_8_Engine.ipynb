{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0265c7f",
   "metadata": {},
   "source": [
    "# Challenge 8 Engine file\n",
    "\n",
    "Ensure this file is in the same directory as Openstates_API_Autocaller.ipynb!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "674d61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e55c9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the main API call for getting legislation data from openstates. See link \n",
    "'https://v3.openstates.org/docs#/bills/bills_search_bills_get' for more information on adding parameters.\n",
    "The funtion takes in a state abbreviation, sponsor/people id, a session year, opt URL, and apikey from the first code block.\n",
    "\n",
    "Notice: Votes and sponsorships are included params. Related_bills seems to be empty for most states.\n",
    "These are placed in row level data as dictionaries that can be sorted further.\n",
    "'''\n",
    "def get_legislation_data(state, page_num, api, people_id = '', session_yr = '', url=\"https://v3.openstates.org/bills\"):\n",
    "    #people_id = 'ocd-person/9877dd5b-c3ee-459f-bb8d-d9d954ae343c'\n",
    "    params = {'apikey': api, \n",
    "              'jurisdiction': state, \n",
    "              #'sponsor': people_id, #used for influencer stories\n",
    "              'sort': 'latest_action_desc',\n",
    "              'page': page_num, \n",
    "              'per_page':20, #limit to 20 per page\n",
    "              #'session' : session_yr, \n",
    "              'include':['votes', 'sponsorships', 'related_bills']}\n",
    "    bills = requests.get(url, params)\n",
    "    \n",
    "    data = bills.json()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Try to access the value corresponding to the key in the dictionary\n",
    "        bill_results = data['results']\n",
    "        page_details = data[\"pagination\"]\n",
    "        \n",
    "        return bill_results, page_details\n",
    "        \n",
    "    except KeyError:\n",
    "        # If KeyError occurs, handle it here\n",
    "        print(\"KeyError: Key results not found in dictionary\")\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c20d9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This simple function is used to take in a state abbreviation and return a hard-coded value for \n",
    "the states current political party information as of 2021 data. Would recommend finding an api source\n",
    "for this to maintain updated info.\n",
    "\n",
    "Purpose: to make a column with state party info to assist the model in determining\n",
    "what bill subjects are likely or less likely to pass.\n",
    "'''\n",
    "def state_party_finder(state):\n",
    "    try:\n",
    "        state_parties = {\n",
    "            \"AL\": \"R\", \n",
    "            \"AK\": \"R\", #works well but 124 pages\n",
    "            \"AZ\": \"D\",\n",
    "            \"AR\": \"R\",\n",
    "            \"CA\": \"D\",\n",
    "            \"CO\": \"D\",\n",
    "            \"CT\": \"D\",\n",
    "            \"DE\": \"D\",\n",
    "            \"FL\": \"R\",\n",
    "            \"GA\": \"R\",\n",
    "            \"HI\": \"D\",\n",
    "            \"ID\": \"R\",\n",
    "            \"IL\": \"D\",\n",
    "            \"IN\": \"R\",\n",
    "            \"IA\": \"R\",\n",
    "            \"KS\": \"R\",\n",
    "            \"KY\": \"R\",\n",
    "            \"LA\": \"R\",\n",
    "            \"ME\": \"D\",\n",
    "            \"MD\": \"D\",\n",
    "            \"MA\": \"D\",\n",
    "            \"MI\": \"D\",\n",
    "            \"MN\": \"D\",\n",
    "            \"MS\": \"R\",\n",
    "            \"MO\": \"R\",\n",
    "            \"MT\": \"R\",\n",
    "            \"NE\": \"R\",\n",
    "            \"NV\": \"D\",\n",
    "            \"NH\": \"D\",\n",
    "            \"NJ\": \"D\",\n",
    "            \"NM\": \"D\",\n",
    "            \"NY\": \"D\",\n",
    "            \"NC\": \"R\",\n",
    "            \"ND\": \"R\",\n",
    "            \"OH\": \"R\",\n",
    "            \"OK\": \"R\",\n",
    "            \"OR\": \"D\",\n",
    "            \"PA\": \"D\",\n",
    "            \"RI\": \"D\",\n",
    "            \"SC\": \"R\",\n",
    "            \"SD\": \"R\",\n",
    "            \"TN\": \"R\",\n",
    "            \"TX\": \"R\",\n",
    "            \"UT\": \"R\",\n",
    "            \"VT\": \"D\",\n",
    "            \"VA\": \"D\",\n",
    "            \"WA\": \"D\",\n",
    "            \"WV\": \"R\",\n",
    "            \"WI\": \"D\",\n",
    "            \"WY\": \"R\"\n",
    "        }\n",
    "\n",
    "        party = state_parties[state.upper()]\n",
    "        return party\n",
    "    except:\n",
    "        print('Please correct state abbreviation!')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8451ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function takes in a list of years, a list of state abbreviations, \n",
    "and a sponsor (person_id). It returns a concat dataframe of the associated bills \n",
    "within that year list range sponsored by the chosen person_id in the specified \n",
    "state/jurisdiction.\n",
    "'''\n",
    "def data_framer(api, state_list, page_start=1, page_end=10, people_id=''):\n",
    "    empty_df = pd.DataFrame()\n",
    "    #collect per year/state, provide first page\n",
    "    for state in state_list:\n",
    "        print('Grabbing data for state: ' + str(state))\n",
    "        try: #catch if empty result and return empty dataframe\n",
    "            #return state party affiliation\n",
    "            state_party = state_party_finder(state)\n",
    "            \n",
    "            bills_json, page_info = get_legislation_data(state, 1, api)\n",
    "\n",
    "            #collect per year/state\n",
    "            max_page = page_info['max_page']\n",
    "            \n",
    "            print('Max pages for state ' + str(state) + ': '+ str(max_page))\n",
    "            \n",
    "        except TypeError: #investigate further 4/7/23\n",
    "            print('bill results empty, type error')\n",
    "            \n",
    "        #loop through all pages and concat #changed from max_page to page_end\n",
    "        for page in range(page_start, page_end):\n",
    "            #handler for when user has selected more pages than available\n",
    "            \n",
    "            try:\n",
    "                print('Page results: ' + str(page))\n",
    "                try:\n",
    "                    bills_json, page_info = get_legislation_data(state, page, api)\n",
    "                    cur_page = page_info['page']\n",
    "                    #collect per year/state\n",
    "                    max_page = page_info['max_page']\n",
    "                    #moved 4/8/23\n",
    "                    if page >= max_page:\n",
    "                        print('max page reached! ending call')\n",
    "                        break\n",
    "                    \n",
    "                    bills_df = pd.json_normalize(bills_json)\n",
    "                    \n",
    "                    empty_df = pd.concat([empty_df, bills_df], ignore_index = True)  \n",
    "                    #add column with state party affiliation 4/7/23\n",
    "                    empty_df['state_party_affiliation'] = state_party\n",
    "                except TypeError:\n",
    "                    print('bill results empty, type error')\n",
    "                    #return empty_df\n",
    "            except KeyError:\n",
    "                #print when api limit is reached @250 calls per day\n",
    "                print(\"Key results not found in dictionary, last page: \" + str(page))\n",
    "            \n",
    "    return empty_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69714dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Due to the nature of the assignment, \n",
    "we want to remove any rows that have blank voting info as well as blank bill subject.\n",
    "\n",
    "'''\n",
    "def filter_df(data, col_name):   \n",
    "    try:\n",
    "        df = data.copy()\n",
    "        return df.drop(df[df[col_name].apply(lambda x: len(x)==0)].index)\n",
    "    except (KeyError, AttributeError):\n",
    "        print('API Call limits Exceeded!')\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d5eb9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_to_dataframe(*lists, columns=None):\n",
    "    \"\"\"\n",
    "    Convert one or more lists to a pandas DataFrame.\n",
    "    :param lists: one or more lists to convert\n",
    "    :param columns: list of column names for the DataFrame (optional)\n",
    "    :return: a pandas DataFrame\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for i, lst in enumerate(lists):\n",
    "        data[f\"list_{i+1}\"] = lst\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if columns is not None:\n",
    "        df.columns = columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fbb9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "'''\n",
    "This function takes in a bill indicie and \n",
    "returns the most recent vote instance that took place for the bill.\n",
    "\n",
    "It takes in the main legi_data dataframe and a specific bill indicie \n",
    "and returns the vote instance indicie that is most recent.\n",
    "'''\n",
    "def vote_inst_sorter(data, bill_int):\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    #lists for storage\n",
    "    date_list = []\n",
    "    result_list = []\n",
    "\n",
    "    #iterate each vote instance for passed bill integer\n",
    "    for vote_inst in range(0, len(df.iloc[bill_int]['votes'])):\n",
    "\n",
    "        date_list.append(df.iloc[bill_int]['votes'][vote_inst]['start_date'])\n",
    "\n",
    "    #dates = [datetime.strptime(date_str, \"%Y-%m-%d\") for date_str in date_list]\n",
    "    #dates = [datetime.strptime(date_str.split(\"-\")[0], \"%Y-%m-%dT%H:%M:%S\") for date_str in date_list]\n",
    "    dates = [parse(date_str) for date_str in date_list]\n",
    "    \n",
    "    sorted_dates = sorted(dates, reverse=True)\n",
    "    \n",
    "    #grab the latest/most recent vote instance\n",
    "    latest = str(sorted_dates[0])[0:10] \n",
    "\n",
    "    #run through again to find ID for latest instance to return\n",
    "    for vote_inst in range(0, len(df.iloc[bill_int]['votes'])):\n",
    "        \n",
    "        #obtain start date per instance\n",
    "        start_date = df.iloc[bill_int]['votes'][vote_inst]['start_date']\n",
    "        \n",
    "        if start_date == latest:\n",
    "            \n",
    "            vote_id = df.iloc[bill_int]['votes'][vote_inst]['id']\n",
    "            latest_result = df.iloc[bill_int]['votes'][vote_inst]['result']\n",
    "            \n",
    "            return vote_inst, latest_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c08317",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates columns: 'vote_info', 'vote_counts', 'result'\n",
    "1. gets a list of legislators that support and list that oppose\n",
    "2. uses set() to get name list to avoid duplicate legislators\n",
    "3. grabs only most recent vote instance of the bill to determine pass/fail result from \n",
    "- see vote_inst_sorter for sorting mechanism.     \n",
    "'''\n",
    "def unpack_votes(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    dict_list = []\n",
    "    cnt_list = []\n",
    "    result_list = []\n",
    "    \n",
    "\n",
    "    #iterate over each bill\n",
    "    for bill in range(0, len(df['votes'])):\n",
    "        \n",
    "        \n",
    "        #pass bill to sorter to get latest vote instance indicie\n",
    "        vote_inst_ind, latest_vote_result = vote_inst_sorter(df, bill)\n",
    "        \n",
    "        #vote result 0/1 conversion for better machine learning \n",
    "        \n",
    "        if latest_vote_result == 'pass':\n",
    "            res = 1\n",
    "        elif latest_vote_result == 'fail':\n",
    "            res = 0\n",
    "        else:\n",
    "            res = np.nan\n",
    "        \n",
    "        #save latest vote numeric outcome\n",
    "        result_list.append(res)\n",
    "        \n",
    "        #counters for vote count info\n",
    "        cnt_dict = {'yes': 0, 'no': 0, 'other': 0}\n",
    "        \n",
    "        cnt_dict['yes'] = df.iloc[bill]['votes'][vote_inst_ind]['counts'][0]['value'] #yes\n",
    "        cnt_dict['no'] = df.iloc[bill]['votes'][vote_inst_ind]['counts'][1]['value'] #no\n",
    "        cnt_dict['other'] = df.iloc[bill]['votes'][vote_inst_ind]['counts'][2]['value'] #other\n",
    "        #append vote counts to list\n",
    "        cnt_list.append(cnt_dict)\n",
    "        \n",
    "        #reset per bill\n",
    "        vote_dict = {'support': set(), 'oppose': set(), 'other': set()}\n",
    "        \n",
    "        #if votes info exists, extract voter names and categorize\n",
    "        if len(df.iloc[bill]['votes'][vote_inst_ind]['votes']) != 0:\n",
    "            #print('State has additional voter information! Extracting...')\n",
    "            #iterate over each voter per vote instance ## len(df.iloc[bill]['votes'][vote_inst_ind]['votes'])\n",
    "            for voter in range(0, len(df.iloc[bill]['votes'][vote_inst_ind])):\n",
    "                \n",
    "                #extract vote for voter\n",
    "                vote = df.iloc[bill]['votes'][vote_inst_ind]['votes'][voter]['option']\n",
    "                #extract voter name\n",
    "                voter_name = df.iloc[bill]['votes'][vote_inst_ind]['votes'][voter]['voter_name']\n",
    "\n",
    "                #voter logic\n",
    "                if vote == 'yes':\n",
    "                    #cnt_dict['yes'] += 1\n",
    "                    vote_dict['support'].add(voter_name)\n",
    "\n",
    "                elif vote == 'no':\n",
    "                    #cnt_dict['no'] += 1\n",
    "                    vote_dict['oppose'].add(voter_name)\n",
    "\n",
    "                else:\n",
    "                    #cnt_dict['other'] += 1\n",
    "                    vote_dict['other'].add(voter_name)\n",
    "\n",
    "            # append list of names\n",
    "            dict_list.append(vote_dict)\n",
    "            \n",
    "        else:\n",
    "            #added 4/6/23 testing if logic for scenario when state has no voter names section\n",
    "            dict_list.append(vote_dict)\n",
    "\n",
    "            #print('No voter info found in json \"votes\" section')\n",
    "        \n",
    "    #runs outside of all for loops\n",
    "    df['vote_info'] = dict_list\n",
    "    df['vote_counts'] = cnt_list\n",
    "    df['result'] = result_list\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f64c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract information from the lists and return a new dataframe\n",
    "def extract_info(row):\n",
    "    # Get the length of the list\n",
    "    list_length = len(row['subject'])\n",
    "    \n",
    "    # Create a dictionary to hold the new column names and values\n",
    "    new_cols = {'id': row['id']}\n",
    "    for i in range(list_length):\n",
    "        new_cols[f'bill_subject_{i+1}'] = row['subject'][i]\n",
    "    \n",
    "    # Return a new dataframe with the new columns\n",
    "    return pd.DataFrame(new_cols, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "833182f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates column: bill_party_affiliation\n",
    "this function takes in the json to pd converted dataframe and searches the 'sponsorship' column for bill sponsors. \n",
    "the sponsors are then counted by party affiliation based on keyword and returned as a 0 1. \n",
    "0 = Rep, 1 = Dem.\n",
    "\n",
    "make this loop through entire df each row and return party affiliation\n",
    "'''\n",
    "def party_counter(df):\n",
    "     \n",
    "    #iterate over list of bills\n",
    "        PA_list = [] #the Party Affiliation List\n",
    "        for bill in range(0, len(df)):#not good enough\n",
    "            try:\n",
    "\n",
    "                \n",
    "                rep = 0\n",
    "                dem = 0\n",
    "                #iterate over list of sponsors for bill\n",
    "                sponsor_count = len(df.iloc[bill]['sponsorships'])\n",
    "                for i in range(sponsor_count):\n",
    "\n",
    "                    party_affiliation = df.iloc[bill]['sponsorships'][i]['person']['party']\n",
    "\n",
    "                    if party_affiliation == 'Republican':\n",
    "                        rep += 1\n",
    "                    else: \n",
    "                        dem += 1\n",
    "\n",
    "                #determine which party had more bill support\n",
    "                #this runs each bill\n",
    "                if rep > dem:\n",
    "                    PA_list.append('R')\n",
    "                elif dem > rep: \n",
    "                    PA_list.append('D')\n",
    "                else:\n",
    "                    PA_list.append('U') #tie situation, uni support\n",
    "                #print bill party affiliation information. for testing...\n",
    "                #print('bill # ' + str(bill) + ' ' +  str({'Republicans': rep, 'Democrats': dem}))\n",
    "        \n",
    "            except KeyError:\n",
    "                 #make this have value added to PA list\n",
    "                #print(\"Key person not found in dictionary\")\n",
    "                PA_list.append('NA')\n",
    "            \n",
    "        #create new column to hold list values   \n",
    "        df['bill_party_affiliation'] = PA_list\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6239f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting as json to avoid string character errors that come up when exporting to csv\n",
    "def export_json(data, state_list, p_start, p_end):\n",
    "    #export the data\n",
    "    file_name = 'legi_data_' + str(state_list) + '_sample'\n",
    "\n",
    "    path = ('data\\\\'+ file_name +  '_' + str(p_start) + '-' + str(p_end) + '.json')\n",
    "    \n",
    "    data.to_json(path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b05bb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function combines the above functions into one for ease of api calling. \n",
    "However, this approach will use many api calls. \n",
    "\n",
    "Provide this function your apikey from openstates, a state name,\n",
    "a start page starting at 10 minimum, and a number of times you want to \n",
    "have this function grab the next 10 pages. The time pause between calls\n",
    "is mandatory by openstates api free license calls and is necessary for the program to run.\n",
    "\n",
    "Files are exported as json and not csv due to formatting issues between columns that break csv export.\n",
    "I used dataiku to read in the json files easily and combine into one dataset to test and export a csv from.\n",
    "'''\n",
    "def run_daily_api_limit(api, state_list, p_start, p_end, call_count=5):\n",
    "    for i in range(0, call_count):\n",
    "        \n",
    "        print('pausing for API required 60 seconds to avoid restrictions')\n",
    "        time.sleep(65)\n",
    "        print( 'Run: ' + str(i+1) + ' of ' + str(call_count))\n",
    "        \n",
    "        \n",
    "        df = data_framer(api, state_list, page_start = p_start, page_end = p_end)\n",
    "        print('Bills before filtering for vote/subject info: '  +  str(len(df)))\n",
    "        #filter out blank vote rows\n",
    "        df_filtered_votes = filter_df(df, 'votes')\n",
    "        print('results after filtering votes: ' + str(len(df_filtered_votes)))\n",
    "        #filter out blank bill subject rows\n",
    "        df_filtered_all = filter_df(df_filtered_votes, 'subject')\n",
    "        print('Bills remaining after filtering for vote/subject info: '  +  str(len(df_filtered_all)))\n",
    "        \n",
    "        #for when 10 pages of 20 results each have no subject/vote info\n",
    "        zero_check = len(df_filtered_all)\n",
    "        #if subject/vote filtering returned no bills\n",
    "        if zero_check != 0:\n",
    "            try: #error here means no rows returned after filtering\n",
    "                #print the value counts of results column\n",
    "                #print('Bill Vote results: ' + str(df_filtered_all['results'].value_counts()) )\n",
    "                print('Unpacking Vote Information')   \n",
    "                unpacked_votes_df = unpack_votes(df_filtered_all)\n",
    "                print('Unpacking Subject Information')       \n",
    "                # Apply the function to the dataframe to get a new dataframe with the list contents separated into new columns\n",
    "                unpacked_subject_df = pd.concat([extract_info(row) for _, row in unpacked_votes_df.iterrows()], ignore_index=True)\n",
    "                print('Merging dataframes')\n",
    "                merged_df = unpacked_votes_df.merge(unpacked_subject_df, on='id')\n",
    "                print('Determining Bill Party Affiliations')\n",
    "                final_legi_data = party_counter(merged_df)\n",
    "                print('Exporting Data')\n",
    "\n",
    "                export_json(final_legi_data, state_list, p_start, p_end)\n",
    "                print('Exported file: ' + str(i+1) + ' of ' + str(call_count))\n",
    "                #Grab next 10 pages\n",
    "                p_start += 10\n",
    "                p_end += 10\n",
    "            except (TypeError, KeyError):\n",
    "                print('No rows returned after filtering...')\n",
    "                print('Bill Vote results: ' + str(df_filtered_all['results'].value_counts()) )\n",
    "                print('Unpacking Vote Information...')   \n",
    "                unpacked_votes_df = unpack_votes(df_filtered_all)\n",
    "                print('Unpacking Subject Information...')       \n",
    "                # Apply the function to the dataframe to get a new dataframe with the list contents separated into new columns\n",
    "                unpacked_subject_df = pd.concat([extract_info(row) for _, row in unpacked_votes_df.iterrows()], ignore_index=True)\n",
    "                print('Merging dataframes...')\n",
    "                merged_df = unpacked_votes_df.merge(unpacked_subject_df, on='id')\n",
    "                print('Determining Bill Party Affiliations...')\n",
    "                final_legi_data = party_counter(merged_df)\n",
    "                print('Empty Data exported!')\n",
    "\n",
    "                export_json(final_legi_data, state_list, p_start, p_end)\n",
    "                #Grab next 10 pages\n",
    "                p_start += 10\n",
    "                p_end += 10\n",
    "                print('API call limits Exceeded')\n",
    "        else: \n",
    "            print('No vote or subject information after filtering bills, moving to next 10 pages...')\n",
    "            #Grab next 10 pages\n",
    "            p_start += 10\n",
    "            p_end += 10\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
